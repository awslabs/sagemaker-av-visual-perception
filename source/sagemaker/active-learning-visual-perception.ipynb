{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual perception for autonomous vehicles using active learning\n",
    "\n",
    "Training computer vision models for autonomous driving to achieve high-end performance requires large labeled datasets, which can be prohibitively expensive. This notebook shows an end to end pipeline that streamlines the process of labelling driving scene datasets for a task, using SageMaker Groundtruth autolabelling and active learning. The task that we focus is pedestrian detection in camera images. This is framed as an object detection task where the goal of the final trained model is to predict 2D bounding boxes around pedestrians in an image.\n",
    "\n",
    "The active learning pipeline ensures that, starting with just a handful of a labels we can train a model, predict bounding boxes, compare the models predictions to a real labels and only add more labels if we need to increase the performance of the model. Using Step Functions, we can create a workflow that automates this process and iteratively performs the active learning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash setup.sh\n",
    "\n",
    "import sagemaker\n",
    "from package import config, manifest\n",
    "\n",
    "role = config.role\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The image dataset we are using for this demonstration is a subset of the [A2D2 dataset](https://www.a2d2.audi/a2d2/en/dataset.html). We select a subset of camera frames from the original dataset and have generated 2D bounding box labels around objects of interests from the segmentation maps in the original dataset. \n",
    "\n",
    "For flexibility and ease of use, we will be working with an S3 manifest file of the dataset. You can replace the `data_manifest_file` with an s3 or local path to your custom manifest file in the same format to use your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manifest_file = 's3://{}/{}/{}'.format(config.solution_upstream_bucket,\n",
    "                                            config.solution_name,\n",
    "                                            'data/manifests/a2d2_visual_perception_bbox.manifest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at single entry in the manifest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_rows = manifest.get_manifest_rows_from_path(data_manifest_file)\n",
    "manifest_rows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and visualize some images that have annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest.visualize_manifest_images(data_manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Groundtruth Labeling Workteam\n",
    "\n",
    "Now that we have seen what data we will be working with. Let's prepare a SageMaker Groundtruth private workteam that we will use as the workforce for data labeling. For the purposes of this demonstration, you will add yourself to a SageMaker private workteam that's managed by a Cognito User Pool. Then when we create labeling jobs during the active learning pipeline, the jobs will be sent to this workteam and you'll be able to go and manually label images using the SageMaker Groundtruth labeling UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a work team\n",
    "\n",
    "The first step is to create a workteam. By launching this solution the necessary Cognito resources for create a new private workteam should have already been created. If you have already used GroundTruth before and set up a Private Workforce, the new workteam will be created against the existing Groundtruth Cognito configuration. However, if there are no existing Cognito configurations for labeling jobs, we will used the Cognito resources created when launching the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from package import workteam\n",
    "\n",
    "cognito_config = workteam.get_cognito_configs()\n",
    "workteam_name = config.solution_prefix + \"-workteam\"\n",
    "\n",
    "if cognito_config is None:\n",
    "    workteam_arn = workteam.create_groundtruth_workteam(workteam_name, config)\n",
    "    userpool = config.cognito_user_pool\n",
    "else:\n",
    "    workteam_arn = workteam.create_groundtruth_workteam(workteam_name, cognito_config)\n",
    "    userpool = cognito_config['UserPool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update your user invitation email with the new workteam\n",
    "\n",
    "Now your private groundtruth workteam is ready to go. Now we'll setup the domain for the Groundtruth labeling jobs that and also update the backing Cognito user pool with this domain. You'll be able to use this to invite people to help you label your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signup_domain = workteam.get_signup_domain(workteam_name=workteam_name)\n",
    "\n",
    "workteam.update_user_pool_with_invite(userpool, signup_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invite yourself and others to label your dataset\n",
    "\n",
    "Invite people to help you label your dataset. Use the following link to enter your email\n",
    "address to get an invite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://{}.console.aws.amazon.com/sagemaker/groundtruth?region={}#/labeling-workforces/add-workers\".format(config.region, config.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then open the following link in a new tab to add your email address to the workteam. \n",
    "\n",
    "Click on the **Workers** tab, then click add worker to add your email address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://{}.console.aws.amazon.com/sagemaker/groundtruth?region={}#/labeling-workforces/private-details/{}\".format(config.region, config.region, workteam_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for Active Learning\n",
    "\n",
    "Now, we will prepare the dataset for the active learning loop. For this, we start with a manifest file that is partially labeled. Starting with this allows us to have the first stage of the Active Learning loop be a model training job instead of a processing job. We could also start with a fully unlabeled dataset but this would mean the first stage of our active learning loop would be a labeling job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload partially labeled input to S3\n",
    "\n",
    "The utility function below will copy the `data_manifest_file` into an input manifest for this experiment. In the input manifest, we will only keep bounding box labels for a subset of the data, and exclude other class labels besides Pedestrians before uploading the input manifest to the s3 path in `input_data`.\n",
    "\n",
    "To see the input manifest, you can open the file `./manifests/partially_labeled_input.manifest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.active_learning import prepare\n",
    "\n",
    "input_data = 's3://{}/{}/{}'.format(config.solution_bucket, 'active-learning', config.s3_data_prefix)\n",
    "s3_input_manifest_path = prepare.partially_labeled_input(input_data, manifest_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the job template and class_labels that will be used by all GroundTruth labeling job in the Active Learning loop. You can see the contents of the template at `./artifacts/instructions.template` and the simple class labels for Pedestrian bounding box at `./artifacts/class_labels.json` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.active_learning import prepare\n",
    "\n",
    "s3_class_labels_path, s3_template_path = prepare.labels_config_and_template(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our input data artifacts in the s3 input location, it is time to create the input request to the active learning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Groundtruth request for active learning \n",
    "\n",
    "The input request to the active learning loop will be in the form of the [GroundTruth Labeling Job request syntax](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateLabelingJob.html) but this will be passed as in input to the Step Functions StateMachine for the active learning loop. The stateMachine will be able to parse the request and select the appropriate state of the active learning loop to begin execution.\n",
    "\n",
    "You can see the input request at the path `./requests/ground_truth.request`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.active_learning import request\n",
    "\n",
    "gt_request = request.create_ground_truth_request(s3_input_manifest_path,\n",
    "                                                 s3_class_labels_path,\n",
    "                                                 s3_template_path,\n",
    "                                                 config.region,\n",
    "                                                 role,\n",
    "                                                 config.solution_prefix,\n",
    "                                                 's3://{}/{}/output/'.format(config.solution_bucket, config.s3_data_prefix),\n",
    "                                                 workteam_arn=workteam_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Active Learning Loop\n",
    "\n",
    "All the input configurations are complete so we can create a new instance of the active learning pipeline and start execution. As mentioned already, we are using a Step Functions workflow to orchestrate the active learning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.active_learning.step_functions import ActiveLearningPipeline\n",
    "\n",
    "step_functions_pipeline = ActiveLearningPipeline(config.step_functions_active_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_arn = step_functions_pipeline.start_execution(gt_request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
